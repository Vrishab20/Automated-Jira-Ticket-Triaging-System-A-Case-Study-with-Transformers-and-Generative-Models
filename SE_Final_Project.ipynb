{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**CSI5137 - Applications of NLP and ML in Software engineering**\n",
        "#**Final Course Project**\n",
        "\n",
        "**Mohammad Bin Yousuf - CU# 101239019**\n",
        "\n",
        "**Vrishab Prasanth Davey - UO# 300438343**\n",
        "\n",
        "**Surendar Pala Dana Sekaran - UO#300401916**\n"
      ],
      "metadata": {
        "id": "UxPkL3Sl43kD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing the libraries"
      ],
      "metadata": {
        "id": "FAwInvX_217c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pickle\n",
        "import os\n",
        "import nlpaug.augmenter.word as naw\n",
        "import numpy as np\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "ARPB_CAWbr8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "k08FoRO33IdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'jira_flattened_results_clean.csv'\n",
        "jira_data = pd.read_csv(file_path)\n",
        "\n",
        "# Selecting relevant columns\n",
        "useful_columns = [\n",
        "    'fields_summary', 'fields_description', 'fields_priority_name',\n",
        "    'fields_issuetype_name', 'fields_labels'\n",
        "]\n",
        "jira_data = jira_data[useful_columns]\n",
        "\n",
        "# Handling missing values\n",
        "jira_data['fields_summary'] = jira_data['fields_summary'].fillna('')\n",
        "jira_data['fields_description'] = jira_data['fields_description'].fillna('')\n",
        "jira_data['fields_labels'] = jira_data['fields_labels'].fillna('')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "jira_data['fields_summary'] = jira_data['fields_summary'].apply(preprocess_text)\n",
        "jira_data['fields_description'] = jira_data['fields_description'].apply(preprocess_text)\n",
        "\n",
        "jira_data['text_combined'] = jira_data['fields_summary'] + \" \" + jira_data['fields_description']\n",
        "\n",
        "jira_data.to_csv('preprocessed_jira_data.csv', index=False)"
      ],
      "metadata": {
        "id": "vcPtgyy5bzZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bug Classification Task"
      ],
      "metadata": {
        "id": "r7vK1j3E3-zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def preprocess_data(X, y, tokenizer, max_length=128):\n",
        "\n",
        "    unique_labels = y.unique()\n",
        "    label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "    encodings = tokenizer(\n",
        "        X.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "    labels = [label_to_id[label] for label in y]\n",
        "\n",
        "    return {\n",
        "        'input_ids': encodings['input_ids'],\n",
        "        'attention_mask': encodings['attention_mask'],\n",
        "        'labels': labels\n",
        "    }, label_to_id\n",
        "\n",
        "X_classification = jira_data['text_combined']\n",
        "y_classification = jira_data['fields_issuetype_name']\n",
        "\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
        "    X_classification, y_classification, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "train_encodings, label_to_id = preprocess_data(X_train_class, y_train_class, tokenizer)\n",
        "test_encodings, _ = preprocess_data(X_test_class, y_test_class, tokenizer)\n",
        "\n",
        "train_dataset = Dataset.from_dict(train_encodings)\n",
        "test_dataset = Dataset.from_dict(test_encodings)\n",
        "\n",
        "num_labels = len(label_to_id)\n",
        "\n",
        "# Load BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label={v: k for k, v in label_to_id.items()},\n",
        "    label2id=label_to_id\n",
        ").to(device)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction function\n",
        "def predict_bert(texts, model, tokenizer, device):\n",
        "\n",
        "    model.eval()\n",
        "    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt').to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encodings)\n",
        "        predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    return [model.config.id2label[pred.item()] for pred in predictions]\n",
        "\n",
        "y_pred_class = predict_bert(X_test_class.tolist(), model, tokenizer, device)\n",
        "\n",
        "classification_metrics = classification_report(y_test_class, y_pred_class, output_dict=True)\n",
        "\n",
        "def print_classification_metrics(metrics):\n",
        "\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n",
        "\n",
        "    for class_name, class_metrics in metrics.items():\n",
        "        if class_name not in ['accuracy', 'macro avg', 'weighted avg']:\n",
        "            table.add_row([\n",
        "                class_name,\n",
        "                f\"{class_metrics['precision']:.3f}\",\n",
        "                f\"{class_metrics['recall']:.3f}\",\n",
        "                f\"{class_metrics['f1-score']:.3f}\",\n",
        "                int(class_metrics['support'])\n",
        "            ])\n",
        "\n",
        "    table.add_row(['-' * 10, '-' * 10, '-' * 10, '-' * 10, '-' * 10])\n",
        "\n",
        "    macro_avg = metrics['macro avg']\n",
        "    table.add_row([\n",
        "        'Macro Avg',\n",
        "        f\"{macro_avg['precision']:.3f}\",\n",
        "        f\"{macro_avg['recall']:.3f}\",\n",
        "        f\"{macro_avg['f1-score']:.3f}\",\n",
        "        int(macro_avg['support'])\n",
        "    ])\n",
        "\n",
        "    weighted_avg = metrics['weighted avg']\n",
        "    table.add_row([\n",
        "        'Weighted Avg',\n",
        "        f\"{weighted_avg['precision']:.3f}\",\n",
        "        f\"{weighted_avg['recall']:.3f}\",\n",
        "        f\"{weighted_avg['f1-score']:.3f}\",\n",
        "        int(weighted_avg['support'])\n",
        "    ])\n",
        "\n",
        "    # Overall accuracy\n",
        "    table.add_row([\n",
        "        'Accuracy',\n",
        "        '',\n",
        "        '',\n",
        "        f\"{metrics['accuracy']:.3f}\",\n",
        "        ''\n",
        "    ])\n",
        "\n",
        "    print(\"Classification Metrics:\")\n",
        "    print(table)\n",
        "\n",
        "print_classification_metrics(classification_metrics)\n",
        "\n",
        "model.save_pretrained('./bert_classification_model')\n",
        "tokenizer.save_pretrained('./bert_classification_tokenizer')\n",
        "\n",
        "with open('label_mapping.pkl', 'wb') as f:\n",
        "    pickle.dump(label_to_id, f)"
      ],
      "metadata": {
        "id": "GZMOxCgBb7dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bug Prioritization Task"
      ],
      "metadata": {
        "id": "pr7R_ZGU3S-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_priority = jira_data['text_combined']\n",
        "y_priority = jira_data['fields_priority_name']\n",
        "\n",
        "# Label encoding\n",
        "label_encoder_priority = LabelEncoder()\n",
        "y_priority_encoded = label_encoder_priority.fit_transform(y_priority)\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "X_train_priority, X_temp_priority, y_train_priority, y_temp_priority = train_test_split(\n",
        "    X_priority, y_priority_encoded, test_size=0.3, random_state=42, stratify=y_priority_encoded\n",
        ")\n",
        "X_val_priority, X_test_priority, y_val_priority, y_test_priority = train_test_split(\n",
        "    X_temp_priority, y_temp_priority, test_size=0.5, random_state=42, stratify=y_temp_priority\n",
        ")\n",
        "\n",
        "class BugPriorityDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Loading the tokenizer and datasets\n",
        "tokenizer_priority = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_dataset_priority = BugPriorityDataset(X_train_priority.tolist(), y_train_priority, tokenizer_priority, max_len=128)\n",
        "val_dataset_priority = BugPriorityDataset(X_val_priority.tolist(), y_val_priority, tokenizer_priority, max_len=128)\n",
        "test_dataset_priority = BugPriorityDataset(X_test_priority.tolist(), y_test_priority, tokenizer_priority, max_len=128)\n",
        "\n",
        "# Computing the class weights for imbalanced datasets\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train_priority),\n",
        "    y=y_train_priority\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda')\n",
        "\n",
        "model_priority = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(label_encoder_priority.classes_)\n",
        ")\n",
        "model_priority.to('cuda')\n",
        "\n",
        "# Defining custom loss function with class weights\n",
        "def custom_loss_function(outputs, labels):\n",
        "    logits = outputs.logits\n",
        "    loss = torch.nn.functional.cross_entropy(logits, labels, weight=class_weights)\n",
        "    return loss\n",
        "\n",
        "# Defining custom Trainer\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        \"\"\"\n",
        "        Custom compute_loss to handle weighted cross-entropy loss.\n",
        "        Accepts additional arguments like 'num_items_in_batch' without breaking.\n",
        "        \"\"\"\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        loss = custom_loss_function(outputs, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Defining training arguments\n",
        "training_args_priority = TrainingArguments(\n",
        "    output_dir='./results_priority',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs_priority',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=20,  # Increased epochs for better learning\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "# Initializing the custom trainer\n",
        "trainer_priority = CustomTrainer(\n",
        "    model=model_priority,\n",
        "    args=training_args_priority,\n",
        "    train_dataset=train_dataset_priority,\n",
        "    eval_dataset=val_dataset_priority,\n",
        "    tokenizer=tokenizer_priority,\n",
        "    compute_metrics=lambda p: {\n",
        "        'accuracy': accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1)),\n",
        "        'precision': precision_recall_fscore_support(p.label_ids, np.argmax(p.predictions, axis=1), average='weighted')[0],\n",
        "        'recall': precision_recall_fscore_support(p.label_ids, np.argmax(p.predictions, axis=1), average='weighted')[1],\n",
        "        'f1': precision_recall_fscore_support(p.label_ids, np.argmax(p.predictions, axis=1), average='weighted')[2],\n",
        "    }\n",
        ")\n",
        "\n",
        "trainer_priority.train()\n",
        "results_priority = trainer_priority.evaluate()\n",
        "print(\"Priority Task Metrics:\", results_priority)\n",
        "\n",
        "test_results = trainer_priority.predict(test_dataset_priority)\n",
        "print(\"Test Set Metrics:\", test_results.metrics)\n",
        "\n",
        "model_priority.save_pretrained('./bert_priority_model')\n",
        "tokenizer_priority.save_pretrained('./bert_priority_model')\n",
        "with open('./bert_priority_model/label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder_priority, f)"
      ],
      "metadata": {
        "id": "UIj9u73mb5tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Team Assignment Task"
      ],
      "metadata": {
        "id": "u4msmHt-4O2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "# Predefined team descriptions for assignment\n",
        "team_descriptions = {\n",
        "    \"UI\": \"Handles frontend, user interface design, interaction problems, CSS, HTML issues, and component rendering errors.\",\n",
        "    \"Backend\": \"Responsible for server-side logic, API endpoints, database operations, backend crashes, latency, and authentication failures.\",\n",
        "    \"DevOps\": \"Focuses on infrastructure setup, CI/CD pipelines, cloud deployments, system configuration, containerization issues, and monitoring failures.\",\n",
        "    \"QA\": \"Manages software testing, test automation, bug reporting, regression testing, performance issues, and quality assurance processes.\"\n",
        "}\n",
        "\n",
        "# Computing embeddings for team descriptions\n",
        "team_embeddings = {team: semantic_model.encode(desc, convert_to_tensor=True) for team, desc in team_descriptions.items()}\n",
        "\n",
        "# Assign bug to team using semantic cosine similarity\n",
        "def assign_bug_to_team(text):\n",
        "    augmented_texts = [text]\n",
        "    aug = naw.SynonymAug(aug_src='wordnet', aug_max=3)\n",
        "    augmented_texts += aug.augment(text, n=2)\n",
        "\n",
        "    combined_embedding = torch.mean(\n",
        "        torch.stack([semantic_model.encode(aug_text, convert_to_tensor=True) for aug_text in augmented_texts]),\n",
        "        dim=0\n",
        "    )\n",
        "\n",
        "    similarities = {team: util.cos_sim(combined_embedding, team_embedding).item() for team, team_embedding in team_embeddings.items()}\n",
        "\n",
        "    # Assign the team with the highest similarity score\n",
        "    best_team = max(similarities, key=similarities.get)\n",
        "    return best_team, similarities"
      ],
      "metadata": {
        "id": "I9FmG1pWdVxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to process all 3 tasks"
      ],
      "metadata": {
        "id": "y7F0abCL4nF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved BERT model, tokenizer, and label mapping\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_classification = BertForSequenceClassification.from_pretrained('./bert_classification_model').to(device)\n",
        "tokenizer_classification = BertTokenizer.from_pretrained('./bert_classification_tokenizer')\n",
        "\n",
        "with open('label_mapping.pkl', 'rb') as f:\n",
        "    label_to_id = pickle.load(f)\n",
        "\n",
        "id_to_label = {v: k for k, v in label_to_id.items()}\n",
        "\n",
        "def classify_bug_with_bert(text):\n",
        "    \"\"\"Classify the bug description using the BERT model.\"\"\"\n",
        "    model_classification.eval()\n",
        "    inputs = tokenizer_classification(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_classification(**inputs)\n",
        "        predicted_label_id = torch.argmax(outputs.logits, dim=1).item()\n",
        "        classification = id_to_label[predicted_label_id]\n",
        "    return classification"
      ],
      "metadata": {
        "id": "B6O8Fp7mRKcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_bug(text):\n",
        "    # Classification\n",
        "    classification = classify_bug_with_bert(text)\n",
        "\n",
        "    # Priority\n",
        "    inputs = tokenizer_priority(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {key: val.to('cuda') for key, val in inputs.items()}  # Move to GPU\n",
        "    outputs = model_priority(**inputs)\n",
        "    predicted_label = torch.argmax(outputs.logits, axis=1).item()\n",
        "    priority = label_encoder_priority.inverse_transform([predicted_label])[0]\n",
        "\n",
        "    # Team Assignment\n",
        "    assigned_team = assign_bug_to_team(text)\n",
        "    return classification, priority, assigned_team"
      ],
      "metadata": {
        "id": "guqfr-rzhzvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the model"
      ],
      "metadata": {
        "id": "lkq5vDHH4tXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bug_description = \"allow copy selected lines diff like copy lines diff preview eg use changelog notes commit message\"\n",
        "classification, priority, assigned_team = process_bug(bug_description)\n",
        "print(f\"Classification: {classification}, Priority: {priority}, Assigned Team: {assigned_team[0]}\")"
      ],
      "metadata": {
        "id": "PEA9RyU_h2Cn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}